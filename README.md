# Visual Assistant


Implemented a deep learning model that automatically generates image captions with the goal to help visually impaired people to better understand their surroundings.

The capt_test folder has images upon which training has been done.
The capt.json has 5 captions each for every image.
The code.py has the code which performs Training on input dataset and does Caption Generation including Text Extraction using Pytesseract library.
The caption that is generated gets converted to audio using a Google API.
